{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library Google API & Tools\n",
    "from googleapiclient.discovery import build\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "import json\n",
    "\n",
    "#Data Visualisasion \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#Other Library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFile = open('./credential.json','r');\n",
    "data = json.load(jsonFile);\n",
    "tokenAPI = data['youtubeToken'];\n",
    "channelId = data['channelId'];\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Credentials\n",
    "apiYoutube = tokenAPI\n",
    "idYoutube = channelId\n",
    "serviceName = 'youtube'\n",
    "apiVersion = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create API Youtube Channel\n",
    "youtube = build(serviceName,apiVersion,developerKey=apiYoutube);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function To Get Data API Youtube\n",
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist\n",
    "    Params:\n",
    "\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "\n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist\n",
    "\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "        part='snippet,contentDetails,statistics',\n",
    "        id=','.join(channel_ids))\n",
    "    response = request.execute()\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName=response['items'][i]['snippet']['title'],\n",
    "                    subscribers=response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views=response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos=response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId=response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Get list of video IDs of all videos in the given playlist\n",
    "    Params:\n",
    "\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    playlist_id: playlist ID of the channel\n",
    "\n",
    "    Returns:\n",
    "    List of video IDs of all videos in the playlist\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50)\n",
    "    response = request.execute()\n",
    "\n",
    "    video_ids = []\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "\n",
    "    while more_pages:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token)\n",
    "            response = request.execute()\n",
    "\n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]\n",
    "                                 ['contentDetails']['videoId'])\n",
    "\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    return video_ids\n",
    "\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get video statistics of all videos with given IDs\n",
    "    Params:\n",
    "\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "\n",
    "    Returns:\n",
    "    Dataframe with statistics of videos, i.e.:\n",
    "        'channelTitle', 'title', 'description', 'tags', 'publishedAt'\n",
    "        'viewCount', 'likeCount', 'favoriteCount', 'commentCount'\n",
    "        'duration', 'definition', 'caption'\n",
    "    \"\"\"\n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                             }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "\n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get top level comments as text from all videos with given IDs (only the first 10 comments due to quote limit of Youtube API)\n",
    "    Params:\n",
    "\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "\n",
    "    Returns:\n",
    "    Dataframe with video IDs and associated top level comment in text.\n",
    "\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            comments_in_video = [comment['snippet']['topLevelComment']\n",
    "                                 ['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {\n",
    "                'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "\n",
    "        except:\n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "\n",
    "    return pd.DataFrame(all_comments)\n",
    "\n",
    "\n",
    "def YTDurationToSeconds(duration):\n",
    "    match = re.match('PT(\\d+H)?(\\d+M)?(\\d+S)?', duration).groups()\n",
    "    hours = _js_parseInt(match[0]) if match[0] else 0\n",
    "    minutes = _js_parseInt(match[1]) if match[1] else 0\n",
    "    seconds = _js_parseInt(match[2]) if match[2] else 0\n",
    "    return hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "\n",
    "def YTDurationToSecondsArray(duration):\n",
    "\n",
    "    answer = []\n",
    "\n",
    "    for duration in duration:\n",
    "        match = re.match('PT(\\d+H)?(\\d+M)?(\\d+S)?', duration).groups()\n",
    "        hours = _js_parseInt(match[0]) if match[0] else 0\n",
    "        minutes = _js_parseInt(match[1]) if match[1] else 0\n",
    "        seconds = _js_parseInt(match[2]) if match[2] else 0\n",
    "        answer.append(hours * 3600 + minutes * 60 + seconds)\n",
    "\n",
    "    return pd.DataFrame(answer)\n",
    "\n",
    "# js-like parseInt\n",
    "# https://gist.github.com/douglasmiranda/2174255\n",
    "\n",
    "\n",
    "def _js_parseInt(string):\n",
    "    return int(''.join([x for x in string if x.isdigit()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing Stats Data Channel Youtube\n",
    "channelStats = get_channel_stats(youtube,idYoutube);\n",
    "channelStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playlist ID\n",
    "playlistId = 'PL_mdEMo1RZrsiHbUe43drlb_92i9L8BuQ'\n",
    "videoId = get_video_ids(youtube,playlistId);\n",
    "videoId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Detail Video from Video ID\n",
    "videoYoutubeDetail = get_video_details(youtube,videoId);\n",
    "# videoYoutubeDetail.to_csv(r'data.csv')\n",
    "videoYoutubeDetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Comment From Videos\n",
    "videoComments = get_comments_in_videos(youtube,videoId)\n",
    "videoComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         title  second\n",
      "                      Ada yang tau ini kenapa?     153\n",
      "   boss yang bikin ngantuk saat mengemudi wkwk     492\n",
      "belajar main NFS Most Wanted dari komen kalian     493\n",
      "  Boss paling kasian yang pernah gw lawan wkwk     500\n",
      "                  Curang adalah jalan ninjaku!     516\n",
      "            boss paling bergaya di most wanted     518\n",
      "             Polisinya jadi susah gini cuy....     519\n",
      "                                   bro ('_')??     523\n",
      "              Lexus gua udah sangar nih boss!!     538\n",
      "                 di seruduk pembalap UFC gw...     541\n",
      "                   Mobilnya gw bikin \"Ming\"kem     555\n",
      "                walau ngebug tetep menang bro!     556\n",
      "            Efek kelamaan gak main nih game...     559\n",
      "            Katanya Most Wanted tuh seru ya...     584\n",
      "                 Ngepush sampe ke blacklist 2!     586\n",
      "Udah hampir setahun belom juga tamat (´ ∀ ` *)     645\n",
      "                            Balikin mobil gua!     669\n"
     ]
    }
   ],
   "source": [
    "#Convert Duration Youtube to second integer\n",
    "youtubeDuration = YTDurationToSecondsArray(videoYoutubeDetail['duration'])\n",
    "\n",
    "data = videoYoutubeDetail.assign(second=youtubeDuration)\n",
    "\n",
    "df = data[['title','second']]\n",
    "\n",
    "\n",
    "sortData = df.sort_values(by='second')\n",
    "\n",
    "print(sortData.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Dengan Durasi Terlama Di Playlist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title     walau ngebug tetep menang bro!\n",
       "second                               669\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Video Dengan Durasi Terlama Di Playlist\")\n",
    "df.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Dengan Durasi Terlama Di Playlist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title     Ada yang tau ini kenapa?\n",
       "second                         153\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Video Dengan Durasi Terlama Di Playlist\")\n",
    "df.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
